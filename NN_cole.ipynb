{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from enum import Enum\n",
    "from util import get_split_cols, get_split_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/data/project2/train.csv\")\n",
    "test = pd.read_csv(\"/data/project2/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_train_df = get_split_frame(train)[0]\n",
    "num_test_df = get_split_frame(test)[0]\n",
    "y = num_train_df[\"Total Household Income\"]\n",
    "num_train_df = num_train_df.drop([\"Total Household Income\"], axis=1)\n",
    "#num_train_df = num_train_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuronType(Enum):\n",
    "    INPUT_TO_HIDDEN = 0\n",
    "    OUTPUT = 1\n",
    "    HIDDEN = 2\n",
    "    \n",
    "    \n",
    "\n",
    "class Neuron(object):\n",
    "    def __init__(self, weights, use_activation = True, neuron_type = NeuronType.HIDDEN):\n",
    "        self.output = None\n",
    "        self.deltas = None\n",
    "        self.sum_w_h = None\n",
    "        self.weights = np.array(weights)\n",
    "        self.use_activation = use_activation\n",
    "        self.neuron_type = neuron_type\n",
    "class NN(object):\n",
    "    def __init__(self, num_input_nodes, num_hidden_nodes, \n",
    "                 num_output_nodes, num_hidden_layers, eta,\n",
    "                 use_activation_on_output = False, activation_name = \"relu\"):\n",
    "        self.outputs = None\n",
    "        self.activation_name = activation_name\n",
    "        self.sum_error = 0\n",
    "        self.eta = eta\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_hidden_nodes = num_hidden_nodes\n",
    "        self.num_output_nodes = num_output_nodes\n",
    "        # hidden layer1 -> input to hidden\n",
    "        self.network = [self.create_randomized_layer_section(num_input_nodes, \n",
    "                                                             num_hidden_nodes, \n",
    "                                                             False, \n",
    "                                                             NeuronType.INPUT_TO_HIDDEN)]\n",
    "        # remaining hidden layers -> hidden to hidden\n",
    "        self.network += [self.create_randomized_layer_section(num_hidden_nodes, \n",
    "                                                              num_hidden_nodes) for _ in range(num_hidden_layers - 1)]\n",
    "        # output -> hidden to output\n",
    "        self.network += [self.create_randomized_layer_section(num_hidden_nodes, \n",
    "                                                              num_output_nodes, \n",
    "                                                              use_activation_on_output, \n",
    "                                                              NeuronType.OUTPUT)]\n",
    "\n",
    "    def create_randomized_layer_section(self, num_inputs, num_nodes, use_activation = True, neuron_type = NeuronType.HIDDEN):\n",
    "        return [Neuron(np.random.rand(num_inputs), use_activation, neuron_type) for idx in range(num_nodes)]\n",
    "    \n",
    "    def activation(self, sum_w_h):\n",
    "        if self.activation_name == \"sigmoid\":\n",
    "            return 1/ (1 + np.exp(-np.int64(sum_w_h)))\n",
    "        if self.activation_name == \"relu\":\n",
    "            return sum_w_h if sum_w_h > 0 else 0\n",
    "        \n",
    "    def d_activation(self, sum_w_h):\n",
    "        if self.activation_name == \"sigmoid\":\n",
    "            return sum_w_h - sum_w_h**2\n",
    "        if self.activation_name == \"relu\":\n",
    "            return 1 if sum_w_h > 0 else 0\n",
    "        \n",
    "    def calc_sum_w_h(self, neuron, prev_outputs):\n",
    "        return np.dot(neuron.weights,prev_outputs)\n",
    "    \n",
    "    def calc_neuron_output(self, neuron, prev_outputs):\n",
    "        neuron.sum_w_h = self.calc_sum_w_h(neuron, prev_outputs)\n",
    "        neuron.output = self.activation(neuron.sum_w_h) if neuron.use_activation else neuron.sum_w_h\n",
    "        return neuron\n",
    "        \n",
    "    def calc_new_layer_outputs (self, layer, prev_outputs, expected = None): \n",
    "        return [self.calc_neuron_output(neuron, prev_outputs) for neuron in layer]\n",
    "    \n",
    "    def forward(self, input_layer, flag=False):\n",
    "        if flag:\n",
    "            self.network = [input_layer] + self.network\n",
    "        for layer_index in range(len(self.network) - 1):\n",
    "            prev_outputs = np.array(self.network[layer_index]) if type(self.network[layer_index][0]) == int\\\n",
    "            or type(self.network[layer_index][0]) == np.int64\\\n",
    "            or type(self.network[layer_index][0]) == np.float128 else np.array([neuron.output for neuron in self.network[layer_index]]) \n",
    "            self.network[layer_index + 1] = self.calc_new_layer_outputs(self.network[layer_index + 1], prev_outputs)\n",
    "#             for neuron in self.network[layer_index + 1]:\n",
    "#                 print(neuron.output)\n",
    "    \n",
    "    def calc_delta(self, neuron, inputs, expected, prev_layer, neuron_index = None):\n",
    "        if neuron_index != None:\n",
    "#             print(neuron_index)\n",
    "#             print(prev_layer[0].__dict__)\n",
    "            prev_deltas = np.array([prev_neuron.deltas[neuron_index] for prev_neuron in prev_layer]) \n",
    "        if neuron.neuron_type == NeuronType.OUTPUT:\n",
    "#             print(\"output set\")\n",
    "#             print(neuron.weights)\n",
    "#             print(expected)\n",
    "#             print(neuron.output)\n",
    "            neuron.deltas = np.array(neuron.weights*(neuron.output - expected), dtype=np.float128)\n",
    "        elif neuron.neuron_type == NeuronType.HIDDEN:\n",
    "            neuron.deltas = neuron.weights*self.d_activation(neuron.sum_w_h)\n",
    "        else:\n",
    "#             print(\"should hit\")\n",
    "#             print(inputs)\n",
    "#             print(self.d_activation(neuron.sum_w_h))\n",
    "            #act = self.d_activation(neuron.sum_w_h)\n",
    "\n",
    "            neuron.deltas = np.array(inputs*self.d_activation(neuron.sum_w_h), dtype=np.float128)\n",
    "#         print(neuron.neuron_type)\n",
    "#         print(prev_deltas)\n",
    "            if len(neuron.deltas) == 0:\n",
    "                neuron.deltas = np.zeros(len(inputs))\n",
    "        if neuron.neuron_type != NeuronType.OUTPUT:\n",
    "            neuron.deltas = np.array([sum(delta*prev_deltas) for delta in neuron.deltas], dtype=np.float128)\n",
    "#         print(\"start\")\n",
    "#         print(neuron.weights)\n",
    "        neuron.weights = neuron.weights - self.eta*neuron.deltas\n",
    "        #print(neuron.weights)\n",
    "        return neuron\n",
    "\n",
    "    def backward(self, inputs, expected):\n",
    "        for layer_index in reversed(range(1,len(self.network))):\n",
    "            if layer_index == len(self.network) - 1:\n",
    "                #print(self.network[layer_index][0].output)\n",
    "                self.network[layer_index] = [self.calc_delta(neuron, inputs, expected, None) for neuron in self.network[layer_index]]\n",
    "            else:\n",
    "                prev_layer = self.network[layer_index + 1]\n",
    "                cur_layer = self.network[layer_index]\n",
    "                self.network[layer_index] = [self.calc_delta(cur_layer[neuron_index], inputs, \n",
    "                                                             expected, prev_layer, \n",
    "                                                             neuron_index) for neuron_index in range(len(cur_layer))]\n",
    "                    \n",
    "                    \n",
    "    def train2(self):\n",
    "        data = [[1, 1],[2, 2],[3, 3],[4, 4],[5, 5],[6, 6],[7, 7],[8, 8],[9, 9],[10, 10],[11, 11],[12, 12],[13, 13],[14, 14],[15, 15],[16, 16],[17, 17],[18, 18],[19, 19],[20, 20],[21, 21],[22, 22],[23, 23],[24, 24],[25, 25],[26, 26],[27, 27],[28, 28],[29, 29],[30, 30],[31, 31],[32, 32],[33, 33],[34, 34],[35, 35],[36, 36],[37, 37],[38, 38],[39, 39],[40, 40],[41, 41],[42, 42],[43, 43],[44, 44],[45, 45],[46, 46],[47, 47],[48, 48],[49, 49],[50, 50],[51, 51],[52, 52],[53, 53],[54, 54],[55, 55],[56, 56],[57, 57],[58, 58],[59, 59],[60, 60],[61, 61],[62, 62],[63, 63],[64, 64],[65, 65],[66, 66],[67, 67],[68, 68],[69, 69],[70, 70],[71, 71],[72, 72],[73, 73],[74, 74],[75, 75],[76, 76],[77, 77],[78, 78],[79, 79],[80, 80],[81, 81],[82, 82],[83, 83],[84, 84],[85, 85],[86, 86],[87, 87],[88, 88],[89, 89],[90, 90],[91, 91],[92, 92],[93, 93],[94, 94],[95, 95],[96, 96],[97, 97],[98, 98],[99, 99],[100, 100]]\n",
    "        expected = [2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86,88,90,92,94,96,98,100,102,104,106,108,110,112,114,116,118,120,122,124,126,128,130,132,134,136,138,140,142,144,146,148,150,152,154,156,158,160,162,164,166,168,170,172,174,176,178,180,182,184,186,188,190,192,194,196,198,200]\n",
    "        data = np.array(data, dtype=np.float128)\n",
    "        \n",
    "        for epoch in range(100):\n",
    "            self.sum_error = 0\n",
    "            for i in range(100):\n",
    "                #print((i+1) + (epoch*10))\n",
    "                self.network = [data[i]] + self.network\n",
    "                self.forward(data[i])\n",
    "                self.backward(data[i], expected[i])\n",
    "                self.network.pop(0)\n",
    "\n",
    "    def train(self, train, y, n_epoch):\n",
    "        for epoch in range(n_epoch):\n",
    "            self.sum_error = 0\n",
    "            for row, expected in zip(train, y):\n",
    "                #print(row)\n",
    "                self.network = [row] + self.network\n",
    "                self.forward(row)\n",
    "                self.backward(row, expected)\n",
    "                self.network.pop(0)\n",
    "                self.sum_error += (self.network[-1][0].output - expected) ** 2\n",
    "            print(self.network[-1][0].output, self.sum_error)\n",
    "                \n",
    "    def predict(self, x):\n",
    "        self.forward(x)\n",
    "        print(self.network[-1][0].output)\n",
    "    \n",
    "    #def calc_\n",
    "            \n",
    "#         self.outputs = outputs\n",
    "#         if expected is not None:\n",
    "#             self.sum_error += sum((expected - outputs)**2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.87734471088\n"
     ]
    }
   ],
   "source": [
    "n = NN(num_input_nodes = 2, num_hidden_nodes = 10, \n",
    "       num_output_nodes = 1, num_hidden_layers = 10, \n",
    "       eta = 0.0000000001, use_activation_on_output = False, \n",
    "       activation_name=\"sigmoid\")\n",
    "\n",
    "n.train2()\n",
    "##n.forward([2,2], True)\n",
    "#n.backward([2,2], 4)\n",
    "n.predict([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-215-040c376adc22>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-215-040c376adc22>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    print(val.strip(\",\") + \"]\")\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "val = []\n",
    "for i in range(1,101):\n",
    "    \n",
    "print(val.strip(\",\") + \"]\")\n",
    "\n",
    "val = \"[\"\n",
    "for i in range(1,101):\n",
    "    val += str(i*2) + \",\"\n",
    "print(val.strip(\",\") + \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = num_train_df.head().as_matrix()\n",
    "yy = y.head().as_matrix()\n",
    "\n",
    "n = NN(num_input_nodes = len(num_train_df.columns), num_hidden_nodes = len(num_train_df.columns) + 1, \n",
    "       num_output_nodes = 1, num_hidden_layers = 10, \n",
    "       eta = 0.000001, use_activation_on_output = False, \n",
    "       activation_name=\"sigmoid\")\n",
    "n.train(x, yy, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'print', 'invalid': 'print', 'over': 'raise', 'under': 'print'}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.seterr(all=\"print\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
